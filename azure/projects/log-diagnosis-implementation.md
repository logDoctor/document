# Log Doctor: ì§„ì°° â†’ êµ¬í˜„ ê°€ì´ë“œ

> Log DoctorëŠ” **ë¡œê·¸ë¥¼ ì§„ì°°(Diagnosis)í•˜ëŠ” ì„œë¹„ìŠ¤**ì…ë‹ˆë‹¤.
> ì˜ì‚¬ê°€ í™˜ìë¥¼ ì§„ì°°í•  ë•Œ "ì–´ë””ê°€ ì•„í”ˆì§€ â†’ ê²€ì‚¬ â†’ íŒë‹¨ â†’ ì²˜ë°©" ìˆœì„œê°€ ìˆë“¯ì´,
> Log Doctorë„ "ë¡œê·¸ ìˆ˜ì§‘ â†’ ì •ê·œí™” â†’ ë¶„ë¥˜ â†’ ì—”ì§„ ì‹¤í–‰" ìˆœì„œë¡œ ë™ì‘í•©ë‹ˆë‹¤.
>
> ì´ ë¬¸ì„œëŠ” [log-standardization.md](log-standardization.md)ì˜ í‘œì¤€í™” ê°œë…ì„  
> `log-doctor-client-back` ì½”ë“œì— **ì–´ë””ì— ì–´ë–»ê²Œ êµ¬í˜„í•˜ëŠ”ê°€**ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## 1. í•µì‹¬ ì›ì¹™: ì§„ì°°ê³¼ ì²˜ë°©ì€ ë¶„ë¦¬í•œë‹¤

```
âŒ ì˜ëª»ëœ ì„¤ê³„: ì§„ì°° â†’ ë°”ë¡œ ì—”ì§„ ì‹¤í–‰ (í•œ íŒŒì´í”„ë¼ì¸ì— ì§ì ‘ ì—°ê²°)

  TimerTrigger â†’ ìˆ˜ì§‘ â†’ ì •ê·œí™” â†’ ë¶„ë¥˜ â†’ ë°”ë¡œ Detect/Retain/Filter/Prevent ì‹¤í–‰
                                          (í•œ ë²ˆì— ì „ë¶€ ì‹¤í–‰ë¨)

  ë¬¸ì œì :
  â”œâ”€â”€ ì§„ì°°ë§Œ í•˜ê³  ì‹¶ì–´ë„ ì—”ì§„ì´ ê°™ì´ ëŒì•„ê°
  â”œâ”€â”€ ì—”ì§„ í•˜ë‚˜ê°€ ì‹¤íŒ¨í•˜ë©´ ì§„ì°°ë„ ë‹¤ì‹œ í•´ì•¼ í•¨
  â”œâ”€â”€ ì§„ì°° ê²°ê³¼ë¥¼ ë‹¤ë¥¸ ê³³(Provider, Teams)ì—ì„œ í™œìš© ë¶ˆê°€
  â””â”€â”€ ì—”ì§„ ì‹¤í–‰ ì£¼ê¸°ê°€ ë‹¤ë¥¸ë° (Detect 30ë¶„, Retain 24ì‹œê°„) ê°•ì œë¡œ ê°™ì´ ëŒì•„ê°
```

```
âœ… ì˜¬ë°”ë¥¸ ì„¤ê³„: ì§„ì°°ê³¼ ì—”ì§„ì„ ì™„ì „ ë¶„ë¦¬

  [ì§„ì°° í”„ë¡œì„¸ìŠ¤]                    [ì—”ì§„ í”„ë¡œì„¸ìŠ¤]
  ì´ˆì§„: ìë™ (ì´ë ¥ ì—†ì„ ë•Œ)           TimerTrigger (ì—”ì§„ë³„ ë‹¤ë¦„)
  ì¬ì§„: ë²„íŠ¼ í´ë¦­ (On-Demand)              â”‚
       â”‚                            Providerì—ì„œ ì •ì±… ìˆ˜ì‹ 
  ìˆ˜ì§‘ â†’ ì •ê·œí™” â†’ ë¶„ë¥˜                     â”‚
       â”‚                            ì €ì¥ëœ ì§„ì°° ê²°ê³¼ë¥¼ ì½ì–´ì„œ ì‹¤í–‰
  ê²°ê³¼ë¥¼ Providerì— ì „ì†¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ (ì§„ì°° ê²°ê³¼ = ì—”ì§„ì˜ "ì°¸ê³  ìë£Œ")
  (Cosmos DBì— ì €ì¥)

  ì¥ì :
  â”œâ”€â”€ ì§„ì°°ë§Œ ëŒë ¤ì„œ "í˜„ì¬ ìƒíƒœ íŒŒì•…"ë§Œ ê°€ëŠ¥ (ë³´ê³ ì„œ ì „ìš©)
  â”œâ”€â”€ ì—”ì§„ë§ˆë‹¤ ë‹¤ë¥¸ ì£¼ê¸°ë¡œ ì‹¤í–‰ ê°€ëŠ¥ (Detect 30ë¶„, Retain 24ì‹œê°„)
  â”œâ”€â”€ ì§„ì°° ê²°ê³¼ë¥¼ Teams ëŒ€ì‹œë³´ë“œì—ì„œ ë°”ë¡œ ì¡°íšŒ ê°€ëŠ¥
  â”œâ”€â”€ ì—”ì§„ ì‹¤íŒ¨í•´ë„ ì§„ì°° ê²°ê³¼ëŠ” ë³´ì¡´ë¨
  â””â”€â”€ LLMì´ ì§„ì°° ê²°ê³¼ë¥¼ ì½ì–´ì„œ Suggestion ìƒì„± ê°€ëŠ¥
```

> [!IMPORTANT] í•µì‹¬ ê·œì¹™
> **ì§„ì°°(Diagnosis)ì€ "í˜„ì¬ ìƒíƒœë¥¼ íŒŒì•…í•˜ê³  ê¸°ë¡"í•˜ëŠ” ê²ƒì´ì§€, ì§ì ‘ ë¬´ì–¸ê°€ë¥¼ ì‹¤í–‰í•˜ì§€ ì•ŠëŠ”ë‹¤.**
> ì—”ì§„ì€ ì§„ì°° ê²°ê³¼ë¥¼ **ì°¸ê³ **í•˜ì—¬ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰í•œë‹¤.

---

## 2. ì§„ì°° ë¹„ìœ : ì˜ì‚¬ vs Log Doctor

```
ì˜ì‚¬ì˜ ì§„ì°° ê³¼ì •                        Log Doctorì˜ ì§„ë‹¨ ê³¼ì •
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â‘  í™˜ìê°€ ì²˜ìŒ ì˜¨ë‹¤ (ì´ˆì§„)               â‘  í…Œë„ŒíŠ¸ ë“±ë¡ (ì´ˆì§„ â€” ìë™)
   â”” "ì²« ë°©ë¬¸ì´ì‹œë„¤ìš”, ê¸°ì´ˆê²€ì‚¬ í•©ì‹œë‹¤"      â”” Cosmosì— ì§„ì°° ì´ë ¥ ì—†ìŒ â†’ ìë™ ì´ˆì§„ ì‹¤í–‰

   ë˜ëŠ”                                  ë˜ëŠ”

   í™˜ìê°€ ë‹¤ì‹œ ì˜¨ë‹¤ (ì¬ì§„)               â‘  ê´€ë¦¬ìê°€ [ì§„ì°° ì‹¤í–‰] ë²„íŠ¼ í´ë¦­ (ì¬ì§„ â€” ìˆ˜ë™)
   â”” "ë‹¤ì‹œ ê²€ì§„ë°›ìœ¼ëŸ¬ ì™”ìŠµë‹ˆë‹¤"              â”” Teams ëŒ€ì‹œë³´ë“œ â†’ Queue ë©”ì‹œì§€ â†’ Agent

â‘¡ ê¸°ì´ˆ ê²€ì‚¬ (í˜ˆì••, ì²´ì˜¨)                â‘¡ ë¡œê·¸ ìˆ˜ì§‘ (Log Collector)
   â”” í‘œì¤€ ì¥ë¹„ë¡œ ìˆ˜ì¹˜í™”                    â”” LAWì—ì„œ KQLë¡œ ìˆ˜ì§‘ â†’ ld_ ìŠ¤í‚¤ë§ˆë¡œ ì •ê·œí™”

â‘¢ ë¶„ë¥˜ (ë‚´ê³¼? ì™¸ê³¼? ì •í˜•?)              â‘¢ ë¶„ë¥˜ (Classifier)
   â”” ì¦ìƒì— ë”°ë¼ ì „ë¬¸ ë¶„ê³¼ë¡œ ë¶„ë¥˜          â”” ëª©ì /ì‹¬ê°ë„/ì¤‘ìš”ë„ë¡œ ë¶„ë¥˜

â‘£ ì§„ë‹¨ì„œ ë°œê¸‰ â† ì—¬ê¸°ì„œ ë!              â‘£ ì§„ì°° ê²°ê³¼ ì €ì¥ â† ì—¬ê¸°ì„œ ë!
   â”” ì°¨íŠ¸ì— ê¸°ë¡                           â”” Providerì— ê²°ê³¼ ì „ì†¡ / Cosmosì— ì €ì¥

       â†• ì‹œê°„ ì°¨ì´ (ë°”ë¡œ ì—°ê²° ì•ˆ ë¨)            â†• ì‹œê°„ ì°¨ì´ (ë°”ë¡œ ì—°ê²° ì•ˆ ë¨)

â‘¤ ì „ë¬¸ì˜ê°€ ì°¨íŠ¸ë¥¼ ë³´ê³  ì§„ë£Œ              â‘¤ ì—”ì§„ì´ ì§„ì°° ê²°ê³¼ë¥¼ ë³´ê³  ì‹¤í–‰
   â”œ ë‚´ê³¼: "í˜ˆë‹¹ ë†’ìœ¼ë‹ˆ ê´€ë¦¬"             â”œ Retain: "ì´ ë¡œê·¸ ë³´ì¡´ ê¸°ê°„ ì¬ì„¤ì •"
   â”œ ì™¸ê³¼: "ìˆ˜ìˆ  í•„ìš”"                   â”œ Detect: "ì´ íŒ¨í„´ ê³µê²© ì§•í›„"
   â”” í”¼ë¶€ê³¼: "ì—°ê³  ì²˜ë°©"                 â”œ Prevent: "Debug ë ˆë²¨ ë„ˆë¬´ ë§ìŒ"
                                        â”” Filter: "ì´ ë…¸ì´ì¦ˆ ì‚­ì œ ì¶”ì²œ"

â‘¥ ì²˜ë°©ì „ ë°œê¸‰                          â‘¥ ë¦¬í¬íŠ¸ ì „ì†¡
   â”” ì•½êµ­ì— ë³´ëƒ„                          â”” Providerì— ê²°ê³¼ ë³´ê³  â†’ Teams ëŒ€ì‹œë³´ë“œ
```

---

## 3. ì½”ë“œ êµ¬ì¡°: ì§„ì°°ê³¼ ì—”ì§„ ì™„ì „ ë¶„ë¦¬

```
log-doctor-client-back/
â”œâ”€â”€ function_app.py                  â† Azure Functions ì§„ì…ì 
â”‚
â””â”€â”€ agent/
    â”œâ”€â”€ handshake.py                 â† Provider ë“±ë¡/ì¸ì¦
    â”œâ”€â”€ core/
    â”‚   â””â”€â”€ config.py
    â”‚
    â”œâ”€â”€ diagnosis/                   â† ğŸ”µ ì§„ì°° (ë…ë¦½ í”„ë¡œì„¸ìŠ¤)
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ runner.py                â† ì§„ì°° ì‹¤í–‰ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
    â”‚   â”œâ”€â”€ collector.py             â† LAWì—ì„œ ë¡œê·¸ ìˆ˜ì§‘
    â”‚   â”œâ”€â”€ normalizer.py            â† ì›ë³¸ â†’ ld_ ìŠ¤í‚¤ë§ˆ ë³€í™˜
    â”‚   â”œâ”€â”€ classifier.py            â† ëª©ì /ì‹¬ê°ë„/ì¤‘ìš”ë„ ë°°ì •
    â”‚   â””â”€â”€ mapping/
    â”‚       â””â”€â”€ table_registry.py    â† LAW í…Œì´ë¸” â†’ ë ˆì´ì–´/ì‹¬ê°ë„ ë§¤í•‘
    â”‚
    â”œâ”€â”€ engines/                     â† ğŸŸ  ì—”ì§„ (ë…ë¦½ í”„ë¡œì„¸ìŠ¤, ì§„ì°°ê³¼ ë³„ê°œ)
    â”‚   â”œâ”€â”€ base.py                  â† BaseEngine
    â”‚   â”œâ”€â”€ detect.py                â† ë³´ì•ˆ ìœ„í˜‘ íƒì§€
    â”‚   â”œâ”€â”€ filter.py                â† ë…¸ì´ì¦ˆ í•„í„°ë§
    â”‚   â”œâ”€â”€ prevent.py               â† ë¡œê·¸ í’ˆì§ˆ ë¶„ì„
    â”‚   â””â”€â”€ retain.py                â† ë³´ì¡´ ê´€ë¦¬
    â”‚
    â””â”€â”€ infra/
        â”œâ”€â”€ auth.py                  â† Managed Identity
        â”œâ”€â”€ azure.py                 â† AzureClient (LAW)
        â””â”€â”€ provider.py              â† ProviderClient
```

> [!NOTE] `pipeline.py` ì œê±°
> ì§„ì°°ê³¼ ì—”ì§„ì´ ë¶„ë¦¬ë˜ë©´ í•˜ë‚˜ì˜ Pipelineìœ¼ë¡œ ë¬¶ì„ ì´ìœ ê°€ ì—†ìŠµë‹ˆë‹¤.
> ëŒ€ì‹  `diagnosis/runner.py`ì™€ ê° ì—”ì§„ì´ ë…ë¦½ ì‹¤í–‰ë©ë‹ˆë‹¤.

---

## 4. ì‹¤í–‰ íë¦„: ì´ˆì§„ / ì¬ì§„ / ì—”ì§„

### 4-1. ì´ˆì§„ â€” ìë™ ì§„ì°° (First Diagnosis)

í…Œë„ŒíŠ¸ ë“±ë¡/Agent í•¸ë“œì…°ì´í¬ ì§í›„, Cosmosì— ì§„ì°° ì´ë ¥ì´ ì—†ìœ¼ë©´ ìë™ ì‹¤í–‰ë©ë‹ˆë‹¤.

```mermaid
sequenceDiagram
    participant Agent as Client Agent
    participant PB as Provider Backend
    participant Cosmos as Cosmos DB
    participant Runner as DiagnosisRunner
    participant LAW as ê³ ê°ì‚¬ LAW

    Note over Agent, Cosmos: í•¸ë“œì…°ì´í¬ ì™„ë£Œ ì§í›„
    Agent->>PB: handshake ì™„ë£Œ
    PB->>Cosmos: ì´ í…Œë„ŒíŠ¸ì˜ ì§„ì°° ì´ë ¥ ì¡°íšŒ
    Cosmos-->>PB: ì—†ìŒ (ì‹ ê·œ)
    PB-->>Agent: ì´ˆì§„ í•„ìš” (run_diagnosis: true)

    Note over Agent, LAW: ìë™ ì´ˆì§„ ì‹¤í–‰
    Agent->>Runner: ì´ˆì§„ ì‹œì‘
    Runner->>LAW: KQLë¡œ ë¡œê·¸ ìˆ˜ì§‘
    LAW-->>Runner: ì›ë³¸ ë¡œê·¸
    Runner->>Runner: ì •ê·œí™” + ë¶„ë¥˜
    Runner->>PB: POST /diagnosis-results
    PB->>Cosmos: ì´ˆì§„ ê²°ê³¼ ì €ì¥
    Note over PB: Teams ëŒ€ì‹œë³´ë“œì— ì´ˆì§„ ê²°ê³¼ í‘œì‹œ
```

### 4-2. ì¬ì§„ â€” ë²„íŠ¼ í´ë¦­ ì§„ì°° (On-Demand Diagnosis)

ê´€ë¦¬ìê°€ Teams ëŒ€ì‹œë³´ë“œì—ì„œ **[ì§„ì°° ì‹¤í–‰]** ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì‹¤í–‰ë©ë‹ˆë‹¤.

```mermaid
sequenceDiagram
    participant Admin as ê´€ë¦¬ì (Teams)
    participant PB as Provider Backend
    participant Queue as Azure Queue
    participant Agent as Client Agent
    participant Runner as DiagnosisRunner
    participant LAW as ê³ ê°ì‚¬ LAW

    Admin->>PB: [ì§„ì°° ì‹¤í–‰] ë²„íŠ¼ í´ë¦­
    PB->>Queue: ì§„ì°° ìš”ì²­ ë©”ì‹œì§€ ì „ì†¡
    Queue->>Agent: QueueTrigger ê¹¨ì–´ë‚¨

    Agent->>Runner: ì¬ì§„ ì‹œì‘
    Runner->>LAW: KQLë¡œ ë¡œê·¸ ìˆ˜ì§‘
    LAW-->>Runner: ì›ë³¸ ë¡œê·¸
    Runner->>Runner: ì •ê·œí™” + ë¶„ë¥˜
    Runner->>PB: POST /diagnosis-results
    PB-->>Admin: ì§„ì°° ì™„ë£Œ ì•Œë¦¼
    Note over Admin: Teams ëŒ€ì‹œë³´ë“œì—ì„œ ê²°ê³¼ í™•ì¸
```

### 4-3. ì—”ì§„ í”„ë¡œì„¸ìŠ¤ (Engines)

ì—”ì§„ì€ ì§„ì°°ê³¼ ë³„ê°œë¡œ ê°ìì˜ ì£¼ê¸°ì— ë”°ë¼ ë…ë¦½ ì‹¤í–‰ë©ë‹ˆë‹¤.

```mermaid
sequenceDiagram
    participant Timer as Engine TimerTrigger (ì—”ì§„ë³„)
    participant Engine as ê° Engine
    participant PB as Provider Backend
    participant LAW as ê³ ê°ì‚¬ LAW

    Timer->>PB: should_i_run? (30ë¶„/6ì‹œê°„/24ì‹œê°„)
    PB-->>Engine: ìŠ¹ì¸ + ì •ì±… + ìµœì‹  ì§„ì°° ê²°ê³¼

    Note over Engine: ì§„ì°° ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ì‹¤í–‰
    Engine->>LAW: ì—”ì§„ë³„ KQL ì¿¼ë¦¬ (í•„ìš” ì‹œ)
    Engine->>Engine: ë¶„ì„/ì²˜ë¦¬
    Engine->>PB: POST /reports (ì‹¤í–‰ ê²°ê³¼)
```

---

## 5. Queue ì¸í”„ë¼: ì§„ì°° ìš”ì²­ì´ Agentì— ë„ë‹¬í•˜ëŠ” ë°©ë²•

### 5-1. AzureWebJobsStorageë€?

Azure Functionsë¥¼ ë°°í¬í•˜ë©´ **ìë™ìœ¼ë¡œ ìƒì„±ë˜ëŠ” Storage Account**ì…ë‹ˆë‹¤. ë³„ë„ë¡œ ë§Œë“¤ í•„ìš” ì—†ìŠµë‹ˆë‹¤.

```
Azure Functions ë°°í¬ ì‹œ ìë™ ìƒì„±:
â”œâ”€â”€ Azure Functions App (Agent)
â”œâ”€â”€ Storage Account (= AzureWebJobsStorage)   â† ì´ê²ƒ!
â”‚   â”œâ”€â”€ Queue Storage                         â† ì§„ì°°/í•„í„° ìš”ì²­ í
â”‚   â”‚   â”œâ”€â”€ diagnosis-requests                â† ğŸ”µ ì§„ì°° ìš”ì²­ í
â”‚   â”‚   â””â”€â”€ filter-requests                   â† ğŸŸ  í•„í„° ì—”ì§„ ìš”ì²­ í
â”‚   â”œâ”€â”€ Blob Storage                          â† Functions ë‚´ë¶€ ìƒíƒœ
â”‚   â””â”€â”€ Table Storage                         â† Functions ë‚´ë¶€ìš©
â””â”€â”€ Application Insights (ì„ íƒ)
```

### 5-2. Providerê°€ ê³ ê°ì‚¬ Queueì— ì ‘ê·¼í•˜ëŠ” ë°©ë²•

```mermaid
sequenceDiagram
    participant Admin as ê´€ë¦¬ì (Teams)
    participant PB as Provider Backend
    participant ClientEntra as Client Entra ID
    participant Queue as ê³ ê°ì‚¬ Storage Queue

    Admin->>PB: [ì§„ì°° ì‹¤í–‰] ë²„íŠ¼ í´ë¦­
    PB->>ClientEntra: OBO í† í°ìœ¼ë¡œ Storage ì ‘ê·¼ í† í° ìš”ì²­
    ClientEntra-->>PB: Storage ì ‘ê·¼ í† í° ë°˜í™˜
    PB->>Queue: Queueì— ë©”ì‹œì§€ ì‚½ì… (ì§„ì°° ìš”ì²­)
    Note over Queue: Agentì˜ QueueTriggerê°€ ë©”ì‹œì§€ë¥¼ ê°ì§€
```

> [!NOTE] Queue ì ‘ê·¼ ê¶Œí•œ
> Providerê°€ ê³ ê°ì‚¬ì˜ Storage Queueì— ë©”ì‹œì§€ë¥¼ ë„£ìœ¼ë ¤ë©´,
> OBO í† í°ì˜ scopeì— `https://storage.azure.com/.default`ê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
> ë˜ëŠ” Agent ë°°í¬ ì‹œ Bicepì—ì„œ Providerì—ê²Œ `Storage Queue Data Message Sender` ì—­í• ì„ ë¶€ì—¬í•©ë‹ˆë‹¤.

### 5-3. Queue ë©”ì‹œì§€ í˜•ì‹

```json
// diagnosis-requests íì— ë“¤ì–´ê°€ëŠ” ë©”ì‹œì§€
{
  "type": "diagnosis",               // "first" (ì´ˆì§„) ë˜ëŠ” "manual" (ì¬ì§„)
  "tenant_id": "tenant-abc",
  "subscription_id": "sub-xyz",
  "requested_by": "admin@contoso.com",
  "requested_at": "2026-02-25T17:00:00+09:00",
  "options": {
    "time_range_hours": 1,            // ìµœê·¼ ëª‡ ì‹œê°„ ë¡œê·¸ë¥¼ ìˆ˜ì§‘í• ì§€
    "tables": ["all"]                 // "all" ë˜ëŠ” íŠ¹ì • í…Œì´ë¸” ëª©ë¡
  }
}
```

---

## 6. ê° ëª¨ë“ˆì˜ ì—­í• ê³¼ ìƒì„¸ êµ¬í˜„

### 6-1. Table Registry â€” LAW í…Œì´ë¸” ë§¤í•‘ ì •ì˜

LAWì—ëŠ” ìˆ˜ì‹­ ê°œì˜ ê¸°ë³¸ í…Œì´ë¸”ì´ ìˆìŠµë‹ˆë‹¤. ê° í…Œì´ë¸”ì´ ì–´ë–¤ ë ˆì´ì–´ì— ì†í•˜ê³ , ì–´ë–¤ í•„ë“œì—ì„œ ì‹¬ê°ë„/ë©”ì‹œì§€ë¥¼ ì¶”ì¶œí•˜ëŠ”ì§€ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

```python
# agent/diagnosis/mapping/table_registry.py

from dataclasses import dataclass
from typing import Callable, Optional

@dataclass
class TableMapping:
    """LAW í…Œì´ë¸” í•˜ë‚˜ì— ëŒ€í•œ ë§¤í•‘ ì •ì˜"""
    table_name: str           # LAW í…Œì´ë¸”ëª…
    layer: str                # "infrastructure" | "runtime" | "application" | "security"
    severity_field: str       # ì‹¬ê°ë„ë¥¼ ì¶”ì¶œí•  ì¹¼ëŸ¼ëª…
    message_field: str        # ë©”ì‹œì§€ë¥¼ ì¶”ì¶œí•  ì¹¼ëŸ¼ëª…
    default_severity: str     # ì‹¬ê°ë„ í•„ë“œê°€ ì—†ì„ ë•Œ ê¸°ë³¸ê°’
    context_fields: list[str] # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•  ì¹¼ëŸ¼ë“¤

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LAW ê¸°ë³¸ í…Œì´ë¸” ë§¤í•‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TABLE_REGISTRY: dict[str, TableMapping] = {

    # â”€â”€ Infrastructure Layer â”€â”€
    "AzureActivity": TableMapping(
        table_name="AzureActivity",
        layer="infrastructure",
        severity_field="Level",           # "Informational", "Warning", "Error"
        message_field="OperationNameValue",
        default_severity="INFO",
        context_fields=["ResourceGroup", "Caller", "CorrelationId",
                        "SubscriptionId", "ResourceProviderValue"],
    ),
    "AzureMetrics": TableMapping(
        table_name="AzureMetrics",
        layer="infrastructure",
        severity_field="_severity_",      # ì—†ìŒ â†’ ê¸°ë³¸ê°’ ì‚¬ìš©
        message_field="MetricName",
        default_severity="INFO",
        context_fields=["ResourceId", "Average", "Maximum", "Minimum"],
    ),
    "AzureDiagnostics": TableMapping(
        table_name="AzureDiagnostics",
        layer="infrastructure",
        severity_field="Level",
        message_field="ResultDescription",
        default_severity="INFO",
        context_fields=["ResourceType", "ResourceId", "OperationName"],
    ),

    # â”€â”€ Runtime Layer â”€â”€
    "AppTraces": TableMapping(
        table_name="AppTraces",
        layer="runtime",
        severity_field="SeverityLevel",   # 0=Verbose, 1=Info, 2=Warning, 3=Error, 4=Critical
        message_field="Message",
        default_severity="INFO",
        context_fields=["AppRoleName", "OperationId",
                        "OperationName", "ClientIP"],
    ),
    "AppExceptions": TableMapping(
        table_name="AppExceptions",
        layer="runtime",
        severity_field="SeverityLevel",
        message_field="OuterMessage",
        default_severity="ERROR",         # ì˜ˆì™¸ëŠ” ê¸°ë³¸ ERROR
        context_fields=["AppRoleName", "ProblemId", "ExceptionType",
                        "Assembly", "Method", "OperationId"],
    ),
    "AppRequests": TableMapping(
        table_name="AppRequests",
        layer="runtime",
        severity_field="_severity_",      # ì—†ìŒ â†’ ResultCodeë¡œ íŒë‹¨
        message_field="Name",
        default_severity="INFO",
        context_fields=["Url", "ResultCode", "DurationMs",
                        "AppRoleName", "OperationId"],
    ),
    "AppDependencies": TableMapping(
        table_name="AppDependencies",
        layer="runtime",
        severity_field="_severity_",      # Success ì—¬ë¶€ë¡œ íŒë‹¨
        message_field="Name",
        default_severity="INFO",
        context_fields=["DependencyType", "Target", "ResultCode",
                        "DurationMs", "Success"],
    ),

    # â”€â”€ Application Layer â”€â”€
    "ContainerLog": TableMapping(
        table_name="ContainerLog",
        layer="application",
        severity_field="LogEntrySource",  # stdout/stderr
        message_field="LogEntry",
        default_severity="INFO",
        context_fields=["ContainerID", "Computer", "Image"],
    ),
    "Syslog": TableMapping(
        table_name="Syslog",
        layer="application",
        severity_field="SeverityLevel",   # "info", "warning", "err", "crit"
        message_field="SyslogMessage",
        default_severity="INFO",
        context_fields=["Computer", "Facility", "ProcessName"],
    ),
    "FunctionAppLogs": TableMapping(
        table_name="FunctionAppLogs",
        layer="application",
        severity_field="Level",
        message_field="Message",
        default_severity="INFO",
        context_fields=["FunctionName", "HostInstanceId", "Category"],
    ),

    # â”€â”€ Security Layer â”€â”€
    "SigninLogs": TableMapping(
        table_name="SigninLogs",
        layer="security",
        severity_field="ResultType",       # 0=ì„±ê³µ, ê·¸ ì™¸=ì‹¤íŒ¨
        message_field="ResultDescription",
        default_severity="INFO",
        context_fields=["UserPrincipalName", "AppDisplayName",
                        "IPAddress", "Location", "ConditionalAccessStatus"],
    ),
    "AADNonInteractiveUserSignInLogs": TableMapping(
        table_name="AADNonInteractiveUserSignInLogs",
        layer="security",
        severity_field="ResultType",
        message_field="ResultDescription",
        default_severity="INFO",
        context_fields=["UserPrincipalName", "AppDisplayName", "IPAddress"],
    ),
    "SecurityEvent": TableMapping(
        table_name="SecurityEvent",
        layer="security",
        severity_field="Level",
        message_field="Activity",
        default_severity="WARNING",
        context_fields=["EventID", "Account", "Computer",
                        "Process", "LogonType"],
    ),
    "AuditLogs": TableMapping(
        table_name="AuditLogs",
        layer="security",
        severity_field="Result",           # "success", "failure"
        message_field="OperationName",
        default_severity="INFO",
        context_fields=["InitiatedBy", "TargetResources", "Category"],
    ),
}
```

### 6-2. Collector â€” LAWì—ì„œ ë¡œê·¸ í•œ ë²ˆ ìˆ˜ì§‘

```python
# agent/diagnosis/collector.py

import logging
from azure.monitor.query import LogsQueryClient, LogsQueryStatus
from azure.core.exceptions import HttpResponseError
from agent.infra.azure import AzureClient
from .mapping.table_registry import TABLE_REGISTRY

logger = logging.getLogger("Collector")

class LogCollector:
    """LAWì—ì„œ ì›ë³¸ ë¡œê·¸ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì±…ì„ë§Œ ê°€ì§„ë‹¤."""

    def __init__(self, azure_client: AzureClient):
        self.azure_client = azure_client

    async def collect(
        self,
        workspace_id: str,
        tables: list[str] | None = None,
        time_range_hours: int = 1,
        max_rows_per_table: int = 5000,
    ) -> list[dict]:
        """
        ì§€ì •ëœ í…Œì´ë¸”ì—ì„œ ìµœê·¼ Nì‹œê°„ ë¡œê·¸ë¥¼ ìˆ˜ì§‘.

        Args:
            workspace_id: LAW ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ID
            tables: ìˆ˜ì§‘í•  í…Œì´ë¸” ëª©ë¡. Noneì´ë©´ TABLE_REGISTRYì˜ ëª¨ë“  í…Œì´ë¸”
            time_range_hours: ìµœê·¼ ëª‡ ì‹œê°„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ì§€
            max_rows_per_table: í…Œì´ë¸”ë‹¹ ìµœëŒ€ í–‰ ìˆ˜ (ë¹„ìš©/ë©”ëª¨ë¦¬ ì œì–´)

        Returns:
            [{"_source_table": "AppTraces", "TimeGenerated": ..., ...}, ...]
        """
        target_tables = tables or list(TABLE_REGISTRY.keys())
        raw_logs = []

        for table in target_tables:
            if table not in TABLE_REGISTRY:
                logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” í…Œì´ë¸”: {table} â€” ê±´ë„ˆëœ€")
                continue

            try:
                kql = (
                    f"{table}"
                    f" | where TimeGenerated > ago({time_range_hours}h)"
                    f" | take {max_rows_per_table}"
                    f" | order by TimeGenerated desc"
                )
                results = await self.azure_client.query_logs(
                    workspace_id, kql
                )

                if results.status == LogsQueryStatus.SUCCESS:
                    for row in results.tables[0].rows:
                        columns = results.tables[0].columns
                        record = {
                            col.name: val
                            for col, val in zip(columns, row)
                        }
                        record["_source_table"] = table
                        raw_logs.append(record)

                    logger.info(f"  âœ“ {table}: {len(results.tables[0].rows)}ê±´")

                elif results.status == LogsQueryStatus.PARTIAL:
                    logger.warning(f"  â–³ {table}: ë¶€ë¶„ ê²°ê³¼ (íƒ€ì„ì•„ì›ƒ)")
                    # ë¶€ë¶„ ê²°ê³¼ë¼ë„ ìˆ˜ì§‘
                    for row in results.partial_data[0].rows:
                        columns = results.partial_data[0].columns
                        record = {
                            col.name: val
                            for col, val in zip(columns, row)
                        }
                        record["_source_table"] = table
                        raw_logs.append(record)

            except HttpResponseError as e:
                if "BadArgumentError" in str(e):
                    # í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš° (ê³ ê°ì‚¬ì— í•´ë‹¹ ë¦¬ì†ŒìŠ¤ê°€ ì—†ìŒ)
                    logger.info(f"  - {table}: í…Œì´ë¸” ì—†ìŒ (ê±´ë„ˆëœ€)")
                else:
                    logger.error(f"  âœ— {table}: ì¿¼ë¦¬ ì‹¤íŒ¨ â€” {e}")

        logger.info(f"ìˆ˜ì§‘ ì™„ë£Œ: ì´ {len(raw_logs)}ê±´ ({len(target_tables)}ê°œ í…Œì´ë¸”)")
        return raw_logs
```

> [!NOTE] í…Œì´ë¸”ì´ ì—†ëŠ” ê²½ìš°
> ê³ ê°ì‚¬ë§ˆë‹¤ ì‚¬ìš©í•˜ëŠ” Azure ì„œë¹„ìŠ¤ê°€ ë‹¤ë¥´ë¯€ë¡œ, LAWì— ì—†ëŠ” í…Œì´ë¸”ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> ì˜ˆ: Application Insightsë¥¼ ì•ˆ ì“°ë©´ `AppTraces`, `AppExceptions` ë“±ì´ ì—†ìŠµë‹ˆë‹¤.
> CollectorëŠ” ì´ë¥¼ **ì—ëŸ¬ê°€ ì•„ë‹Œ ì •ìƒ ìƒí™©**ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  ê±´ë„ˆëœë‹ˆë‹¤.

### 6-3. Normalizer â€” ld_ ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜

```python
# agent/diagnosis/normalizer.py

import logging
from .mapping.table_registry import TABLE_REGISTRY, TableMapping

logger = logging.getLogger("Normalizer")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹¬ê°ë„ ì •ê·œí™” ë§¤í•‘
# LAW í…Œì´ë¸”ë§ˆë‹¤ ì‹¬ê°ë„ í‘œí˜„ì´ ë‹¤ë¥´ë‹¤:
#   AppTraces: 0, 1, 2, 3, 4 (ìˆ«ì)
#   AzureActivity: "Informational", "Warning", "Error" (ë¬¸ìì—´)
#   Syslog: "info", "warning", "err", "crit" (ì†Œë¬¸ì)
#   SigninLogs: ResultType 0=ì„±ê³µ, ë‚˜ë¨¸ì§€=ì‹¤íŒ¨ (ì½”ë“œ)
# ì´ë¥¼ í†µì¼ëœ 5ë‹¨ê³„ë¡œ ë³€í™˜í•œë‹¤.
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SEVERITY_MAP = {
    # AppTraces / AppExceptions (SeverityLevel â€” ìˆ«ì)
    "0": "TRACE", "verbose": "TRACE",
    "1": "INFO",  "information": "INFO", "informational": "INFO",
    "2": "WARNING", "warning": "WARNING", "warn": "WARNING",
    "3": "ERROR", "error": "ERROR", "err": "ERROR",
    "4": "CRITICAL", "critical": "CRITICAL", "crit": "CRITICAL",

    # AzureActivity / AzureDiagnostics (Level â€” ë¬¸ìì—´)
    "information": "INFO",

    # Syslog (SeverityLevel â€” ì†Œë¬¸ì)
    "info": "INFO",
    "notice": "INFO",
    "debug": "DEBUG",
    "emerg": "CRITICAL",
    "alert": "CRITICAL",

    # SigninLogs (ResultType)
    "0": "INFO",          # ë¡œê·¸ì¸ ì„±ê³µ
    "success": "INFO",
    "failure": "WARNING",

    # ContainerLog (LogEntrySource)
    "stdout": "INFO",
    "stderr": "ERROR",
}


class LogNormalizer:
    """LAW ì›ë³¸ ë¡œê·¸ë¥¼ ld_ ê³µí†µ ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜í•œë‹¤."""

    def normalize(self, raw_log: dict) -> dict | None:
        """
        ì›ë³¸ ë¡œê·¸ â†’ ld_ ìŠ¤í‚¤ë§ˆ ë³€í™˜.

        Returns:
            ë³€í™˜ëœ ë¡œê·¸ dict, ë˜ëŠ” ë³€í™˜ ë¶ˆê°€ ì‹œ None
        """
        table = raw_log.get("_source_table")
        if not table or table not in TABLE_REGISTRY:
            return None

        mapping = TABLE_REGISTRY[table]

        return {
            # ê³µí†µ í•„ë“œ
            "ld_timestamp": raw_log.get("TimeGenerated"),
            "ld_source_table": table,
            "ld_layer": mapping.layer,
            "ld_severity": self._extract_severity(raw_log, mapping),
            "ld_message": self._extract_message(raw_log, mapping),

            # ì»¨í…ìŠ¤íŠ¸ (í…Œì´ë¸”ë³„ ì¶”ê°€ ì •ë³´)
            "ld_context": {
                field: raw_log.get(field)
                for field in mapping.context_fields
                if raw_log.get(field) is not None
            },

            # ì›ë³¸ ë³´ì¡´ (í•„ìš” ì‹œ ì—”ì§„ì´ ì°¸ì¡°)
            "raw": raw_log,
        }

    def _extract_severity(self, raw_log: dict, mapping: TableMapping) -> str:
        """ì‹¬ê°ë„ë¥¼ í†µì¼ëœ 5ë‹¨ê³„(TRACE/DEBUG/INFO/WARNING/ERROR/CRITICAL)ë¡œ ë³€í™˜"""
        raw_value = raw_log.get(mapping.severity_field)

        if raw_value is None:
            # â”€â”€ AppRequests: ResultCodeë¡œ ì‹¬ê°ë„ íŒë‹¨ â”€â”€
            if mapping.table_name == "AppRequests":
                code = str(raw_log.get("ResultCode", "200"))
                if code.startswith("5"):
                    return "ERROR"
                elif code.startswith("4"):
                    return "WARNING"
                return "INFO"

            # â”€â”€ AppDependencies: Success í•„ë“œë¡œ íŒë‹¨ â”€â”€
            if mapping.table_name == "AppDependencies":
                return "INFO" if raw_log.get("Success") else "ERROR"

            return mapping.default_severity

        normalized = SEVERITY_MAP.get(str(raw_value).lower().strip())
        return normalized or mapping.default_severity

    def _extract_message(self, raw_log: dict, mapping: TableMapping) -> str:
        """ë©”ì‹œì§€ ì¶”ì¶œ (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)"""
        msg = raw_log.get(mapping.message_field, "")
        if isinstance(msg, str) and len(msg) > 500:
            msg = msg[:500] + "...(truncated)"
        return msg or ""
```

### 6-4. Classifier â€” ëª©ì  / ì¤‘ìš”ë„ ë¶„ë¥˜

```python
# agent/diagnosis/classifier.py

import logging

logger = logging.getLogger("Classifier")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì¤‘ìš”ë„ ì ìˆ˜ ê¸°ì¤€ (log-standardization.md Section 3-2)
# ë ˆì´ì–´ ì ìˆ˜ + ì‹¬ê°ë„ ì ìˆ˜ + ëª©ì  ì ìˆ˜ = ì´ì  â†’ ë“±ê¸‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LAYER_SCORES = {
    "security": 4,
    "infrastructure": 3,
    "runtime": 2,
    "application": 1,
}

SEVERITY_SCORES = {
    "CRITICAL": 5,
    "ERROR": 4,
    "WARNING": 3,
    "INFO": 2,
    "DEBUG": 1,
    "TRACE": 0,
}

PURPOSE_SCORES = {
    "security": 3,     # ë³´ì•ˆ â†’ ë†’ì€ ê°€ì¤‘ì¹˜
    "compliance": 3,   # ê°ì‚¬/ê·œì •
    "operational": 1,  # ì¼ë°˜ ìš´ì˜
    "diagnostic": 0,   # ë””ë²„ê¹…ìš©
}

# ì´ì  â†’ ì¤‘ìš”ë„ ë“±ê¸‰ (0~12 ë²”ìœ„)
def _score_to_criticality(score: int) -> str:
    if score >= 10:
        return "critical"
    elif score >= 7:
        return "high"
    elif score >= 4:
        return "medium"
    elif score >= 2:
        return "low"
    else:
        return "noise"

# ì¤‘ìš”ë„ â†’ Retain ë³´ì¡´ ë“±ê¸‰
CRITICALITY_TO_RETAIN = {
    "critical": "A",   # ìµœëŒ€ ë³´ì¡´ (LAW 14ì¼ + Blob 1ë…„+)
    "high": "A",
    "medium": "B",     # ì¤‘ê°„ ë³´ì¡´ (LAW 14ì¼ + ì‚­ì œ)
    "low": "C",        # ìµœì†Œ ë³´ì¡´ (LAW 7ì¼ + ì‚­ì œ)
    "noise": "C",
}


class LogClassifier:
    """ì •ê·œí™”ëœ ë¡œê·¸ì— ëª©ì (purpose)ê³¼ ì¤‘ìš”ë„(criticality)ë¥¼ ë°°ì •í•œë‹¤."""

    def classify(self, normalized_log: dict) -> dict:
        """
        ì…ë ¥: normalizerê°€ ë§Œë“  ld_ ìŠ¤í‚¤ë§ˆ
        ì¶œë ¥: ld_purpose, ld_criticality, ld_classification ì¶”ê°€ëœ dict
        """
        layer = normalized_log["ld_layer"]
        severity = normalized_log["ld_severity"]

        # â”€â”€ ëª©ì (Purpose) ê²°ì • â”€â”€
        purpose = self._determine_purpose(normalized_log)

        # â”€â”€ ì¤‘ìš”ë„(Criticality) ì ìˆ˜ ê³„ì‚° â”€â”€
        score = (
            LAYER_SCORES.get(layer, 1)
            + SEVERITY_SCORES.get(severity, 2)
            + PURPOSE_SCORES.get(purpose, 1)
        )
        criticality = _score_to_criticality(score)

        # â”€â”€ ì—”ì§„ë³„ í–‰ë™ ê²°ì • â”€â”€
        classification = {
            # Retain: ë³´ì¡´ ë“±ê¸‰
            "retain_class": CRITICALITY_TO_RETAIN[criticality],
            "retain_days_hot": 14 if criticality in ("critical", "high", "medium") else 7,
            "retain_days_archive": 365 if criticality in ("critical", "high") else 0,

            # Filter: í•„í„°ë§ ê°€ëŠ¥ ì—¬ë¶€ (ë³´ì•ˆì€ ì ˆëŒ€ ë¶ˆê°€)
            "filterable": (
                criticality in ("low", "noise")
                and layer != "security"
            ),

            # Detect: ë³´ì•ˆ íƒì§€ ê´€ë ¨ ì—¬ë¶€
            "detect_relevant": layer == "security" or purpose == "security",

            # Prevent: ì˜ˆë°© ë¶„ì„ ëŒ€ìƒ (Debug-in-prod ë“±)
            "prevent_relevant": severity in ("DEBUG", "TRACE"),
        }

        return {
            **normalized_log,
            "ld_purpose": purpose,
            "ld_criticality": criticality,
            "ld_criticality_score": score,
            "ld_classification": classification,
        }

    def _determine_purpose(self, log: dict) -> str:
        """ë¡œê·¸ì˜ ëª©ì ì„ ê²°ì •"""
        layer = log["ld_layer"]
        table = log["ld_source_table"]

        # Security ë ˆì´ì–´ëŠ” ë¬´ì¡°ê±´ ë³´ì•ˆ ëª©ì 
        if layer == "security":
            return "security"

        # ê°ì‚¬ ë¡œê·¸
        if table in ("AuditLogs",):
            return "compliance"

        # Debug/TraceëŠ” ì§„ë‹¨ìš©
        if log["ld_severity"] in ("DEBUG", "TRACE"):
            return "diagnostic"

        # ë‚˜ë¨¸ì§€ëŠ” ìš´ì˜ìš©
        return "operational"
```

### 6-5. DiagnosisRunner â€” ì§„ì°° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°

```python
# agent/diagnosis/runner.py

import logging
from datetime import datetime, timezone
from agent.infra.azure import AzureClient
from .collector import LogCollector
from .normalizer import LogNormalizer
from .classifier import LogClassifier

logger = logging.getLogger("DiagnosisRunner")


class DiagnosisRunner:
    """ì§„ì°°ì˜ ì „ì²´ íë¦„ì„ ì¡°ìœ¨í•œë‹¤: ìˆ˜ì§‘ â†’ ì •ê·œí™” â†’ ë¶„ë¥˜ â†’ ê²°ê³¼ ìƒì„±"""

    def __init__(self, azure_client: AzureClient):
        self.collector = LogCollector(azure_client)
        self.normalizer = LogNormalizer()
        self.classifier = LogClassifier()

    async def run(
        self,
        workspace_id: str,
        tenant_id: str,
        agent_id: str,
        options: dict | None = None,
    ) -> dict:
        """
        ì§„ì°° ì‹¤í–‰ â†’ ê²°ê³¼ dict ë°˜í™˜.

        Returns:
            Providerì— POSTí•  ì§„ì°° ê²°ê³¼
        """
        opts = options or {}
        time_range = opts.get("time_range_hours", 1)
        tables = opts.get("tables")
        if tables == ["all"] or tables is None:
            tables = None  # None â†’ TABLE_REGISTRY ì „ì²´

        logger.info(f"â•â•â• ì§„ì°° ì‹œì‘ (ìµœê·¼ {time_range}ì‹œê°„) â•â•â•")

        # â”€â”€ â‘  ìˆ˜ì§‘ â”€â”€
        logger.info("Phase 1: ë¡œê·¸ ìˆ˜ì§‘...")
        raw_logs = await self.collector.collect(
            workspace_id=workspace_id,
            tables=tables,
            time_range_hours=time_range,
        )

        if not raw_logs:
            logger.warning("ìˆ˜ì§‘ëœ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return self._empty_result(tenant_id, agent_id)

        # â”€â”€ â‘¡ ì •ê·œí™” â”€â”€
        logger.info("Phase 2: ì •ê·œí™”...")
        normalized = []
        for raw in raw_logs:
            result = self.normalizer.normalize(raw)
            if result:
                normalized.append(result)

        logger.info(f"  ì •ê·œí™” ì™„ë£Œ: {len(normalized)}/{len(raw_logs)}ê±´")

        # â”€â”€ â‘¢ ë¶„ë¥˜ â”€â”€
        logger.info("Phase 3: ë¶„ë¥˜...")
        classified = [self.classifier.classify(log) for log in normalized]

        # â”€â”€ â‘£ ê²°ê³¼ ì§‘ê³„ â”€â”€
        logger.info("Phase 4: ê²°ê³¼ ì§‘ê³„...")
        result = self._aggregate(classified, tenant_id, agent_id, time_range)

        logger.info(f"â•â•â• ì§„ì°° ì™„ë£Œ: ì´ {len(classified)}ê±´ ë¶„ì„ â•â•â•")
        return result

    def _aggregate(
        self,
        classified_logs: list[dict],
        tenant_id: str,
        agent_id: str,
        time_range: int,
    ) -> dict:
        """ë¶„ë¥˜ëœ ë¡œê·¸ë¥¼ ì§‘ê³„í•˜ì—¬ ì§„ì°° ê²°ê³¼ë¥¼ ìƒì„±"""

        # í…Œì´ë¸”ë³„ ì¹´ìš´íŠ¸
        tables_scanned = list(set(
            log["ld_source_table"] for log in classified_logs
        ))

        # ë¶„í¬ ê³„ì‚°
        by_layer = {}
        by_criticality = {}
        by_severity = {}
        by_purpose = {}

        for log in classified_logs:
            layer = log["ld_layer"]
            crit = log["ld_criticality"]
            sev = log["ld_severity"]
            purp = log["ld_purpose"]

            by_layer[layer] = by_layer.get(layer, 0) + 1
            by_criticality[crit] = by_criticality.get(crit, 0) + 1
            by_severity[sev] = by_severity.get(sev, 0) + 1
            by_purpose[purp] = by_purpose.get(purp, 0) + 1

        # ì—”ì§„ë³„ íŒíŠ¸
        cls_list = [log["ld_classification"] for log in classified_logs]
        total = len(classified_logs)

        return {
            "tenant_id": tenant_id,
            "agent_id": agent_id,
            "diagnosed_at": datetime.now(timezone.utc).isoformat(),

            "summary": {
                "total_logs_analyzed": total,
                "tables_scanned": tables_scanned,
                "time_range_hours": time_range,
            },

            "distribution": {
                "by_layer": by_layer,
                "by_criticality": by_criticality,
                "by_severity": by_severity,
                "by_purpose": by_purpose,
            },

            "engine_hints": {
                "detect": {
                    "security_log_count": sum(
                        1 for c in cls_list if c["detect_relevant"]
                    ),
                },
                "retain": {
                    "class_a_count": sum(
                        1 for c in cls_list if c["retain_class"] == "A"
                    ),
                    "class_b_count": sum(
                        1 for c in cls_list if c["retain_class"] == "B"
                    ),
                    "class_c_count": sum(
                        1 for c in cls_list if c["retain_class"] == "C"
                    ),
                },
                "filter": {
                    "noise_log_count": sum(
                        1 for c in cls_list if c["filterable"]
                    ),
                    "estimated_cost_savings_percent": round(
                        sum(1 for c in cls_list if c["filterable"])
                        / max(total, 1) * 100, 1
                    ),
                },
                "prevent": {
                    "debug_in_production_count": sum(
                        1 for c in cls_list if c["prevent_relevant"]
                    ),
                },
            },
        }

    def _empty_result(self, tenant_id: str, agent_id: str) -> dict:
        """ë¡œê·¸ê°€ ì—†ì„ ë•Œì˜ ë¹ˆ ê²°ê³¼"""
        return {
            "tenant_id": tenant_id,
            "agent_id": agent_id,
            "diagnosed_at": datetime.now(timezone.utc).isoformat(),
            "summary": {
                "total_logs_analyzed": 0,
                "tables_scanned": [],
                "time_range_hours": 0,
            },
            "distribution": {
                "by_layer": {},
                "by_criticality": {},
                "by_severity": {},
                "by_purpose": {},
            },
            "engine_hints": {
                "detect": {"security_log_count": 0},
                "retain": {"class_a_count": 0, "class_b_count": 0, "class_c_count": 0},
                "filter": {"noise_log_count": 0, "estimated_cost_savings_percent": 0},
                "prevent": {"debug_in_production_count": 0},
            },
        }
```

---

## 7. function_app.py â€” íŠ¸ë¦¬ê±° ë¶„ë¦¬

```python
# function_app.py â€” ì§„ì°°ê³¼ ì—”ì§„ì´ ë³„ë„ íŠ¸ë¦¬ê±°

import json
import logging
import azure.functions as func
from agent.handshake import perform_idempotent_handshake
from agent.infra.azure import AzureClient
from agent.infra.provider import ProviderClient
from agent.diagnosis.runner import DiagnosisRunner
from agent.engines.detect import DetectEngine
from agent.engines.prevent import PreventEngine
from agent.engines.retain import RetainEngine
from agent.engines.filter import FilterEngine

app = func.FunctionApp()
azure_client = AzureClient()
provider_client = ProviderClient()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ”µ ì§„ì°°: On-Demand (ë²„íŠ¼ í´ë¦­ â†’ Queue) + ì´ˆì§„ ìë™
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.queue_trigger(arg_name="msg", queue_name="diagnosis-requests",
                   connection="AzureWebJobsStorage")
async def diagnosis_trigger(msg: func.QueueMessage):
    """
    ì§„ì°° ì „ìš© íŠ¸ë¦¬ê±° (On-Demand).
    - ì´ˆì§„: handshake ì‹œ Providerê°€ Cosmos ì¡°íšŒ â†’ ì´ë ¥ ì—†ìœ¼ë©´ Queueì— ë©”ì‹œì§€ ì „ì†¡
    - ì¬ì§„: ê´€ë¦¬ìê°€ Teams [ì§„ì°° ì‹¤í–‰] ë²„íŠ¼ â†’ Provider â†’ Queue
    ê²°ê³¼: LAW ìˆ˜ì§‘ â†’ ì •ê·œí™” â†’ ë¶„ë¥˜ â†’ Providerì— ê²°ê³¼ë§Œ ì €ì¥.
    """
    request = json.loads(msg.get_body().decode("utf-8"))
    logging.info(f"ì§„ì°° ìš”ì²­ ìˆ˜ì‹ : {request.get('type', 'unknown')}")

    await perform_idempotent_handshake()

    runner = DiagnosisRunner(azure_client)
    diagnosis_result = await runner.run(
        workspace_id=request.get("workspace_id"),
        tenant_id=request["tenant_id"],
        agent_id=request.get("agent_id", "unknown"),
        options=request.get("options"),
    )

    # ì§„ì°° ê²°ê³¼ë§Œ Providerì— ì „ì†¡ (ì—”ì§„ ì‹¤í–‰ X)
    await provider_client.submit_diagnosis(diagnosis_result)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸŸ  ì—”ì§„ íŠ¸ë¦¬ê±°ë“¤: ê°ê° ë‹¤ë¥¸ ì£¼ê¸°. ì§„ì°° ê²°ê³¼ë¥¼ ì°¸ê³ ë§Œ í•¨.
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.timer_trigger(arg_name="mytimer", schedule="0 */30 * * * *")
async def detect_trigger(mytimer: func.TimerRequest):
    """Detect ì—”ì§„ â€” 30ë¶„ ì£¼ê¸° (ë³´ì•ˆ ìœ„í˜‘ì€ ë¹ ë¥¸ ê°ì§€ í•„ìš”)"""
    if await provider_client.should_i_run("detect"):
        policies = await provider_client.get_policies("detect")
        engine = DetectEngine(azure_client)
        result = await engine.run(policies)
        await provider_client.report_result("detect", result)


@app.timer_trigger(arg_name="mytimer", schedule="0 0 */6 * * *")
async def prevent_trigger(mytimer: func.TimerRequest):
    """Prevent ì—”ì§„ â€” 6ì‹œê°„ ì£¼ê¸°"""
    if await provider_client.should_i_run("prevent"):
        policies = await provider_client.get_policies("prevent")
        engine = PreventEngine(azure_client)
        result = await engine.run(policies)
        await provider_client.report_result("prevent", result)


@app.timer_trigger(arg_name="mytimer", schedule="0 0 0 * * *")
async def retain_trigger(mytimer: func.TimerRequest):
    """Retain ì—”ì§„ â€” 24ì‹œê°„ ì£¼ê¸°"""
    if await provider_client.should_i_run("retain"):
        policies = await provider_client.get_policies("retain")
        engine = RetainEngine(azure_client)
        result = await engine.run(policies)
        await provider_client.report_result("retain", result)


@app.queue_trigger(arg_name="msg", queue_name="filter-requests",
                   connection="AzureWebJobsStorage")
async def filter_trigger(msg: func.QueueMessage):
    """Filter ì—”ì§„ â€” On Demand (ê´€ë¦¬ìê°€ ìš”ì²­ ì‹œ)"""
    policies = await provider_client.get_policies("filter")
    engine = FilterEngine(azure_client)
    result = await engine.run(policies)
    await provider_client.report_result("filter", result)
```

---

## 8. ì§„ì°° ê²°ê³¼ ë°ì´í„° êµ¬ì¡° (ìƒì„¸)

Providerì— ì „ì†¡í•˜ëŠ” ì§„ì°° ê²°ê³¼ì˜ í˜•íƒœ:

```json
{
  "tenant_id": "tenant-abc",
  "agent_id": "agent-xyz",
  "diagnosed_at": "2026-02-25T15:00:00+09:00",

  "summary": {
    "total_logs_analyzed": 15420,
    "tables_scanned": [
      "AppTraces", "AppExceptions", "AppRequests",
      "SigninLogs", "AuditLogs", "AzureActivity",
      "AzureDiagnostics", "ContainerLog"
    ],
    "time_range_hours": 1
  },

  "distribution": {
    "by_layer": {
      "infrastructure": 2100,
      "runtime": 5200,
      "application": 7500,
      "security": 620
    },
    "by_criticality": {
      "critical": 620,
      "high": 1300,
      "medium": 3500,
      "low": 4200,
      "noise": 5800
    },
    "by_severity": {
      "ERROR": 450,
      "WARNING": 1200,
      "INFO": 8500,
      "DEBUG": 4200,
      "TRACE": 1070
    },
    "by_purpose": {
      "security": 620,
      "operational": 9300,
      "diagnostic": 5270,
      "compliance": 230
    }
  },

  "engine_hints": {
    "detect": {
      "security_log_count": 620
    },
    "retain": {
      "class_a_count": 1920,
      "class_b_count": 3500,
      "class_c_count": 10000
    },
    "filter": {
      "noise_log_count": 5800,
      "estimated_cost_savings_percent": 37.6
    },
    "prevent": {
      "debug_in_production_count": 5270
    }
  }
}
```

### ì´ ê²°ê³¼ê°€ ì–´ë””ë¡œ í˜ëŸ¬ê°€ëŠ”ê°€

```
  DiagnosisRunner
       â”‚
       â–¼
  Provider Backend (Cosmos DBì— ì €ì¥)
       â”‚
       â”œâ”€â”€â†’ Teams ëŒ€ì‹œë³´ë“œ: "í˜„ì¬ ê³ ê°ì‚¬ ë¡œê·¸ ìƒíƒœ" ì¡°íšŒ
       â”‚       â”” "ë…¸ì´ì¦ˆ 37.6%, Debug-in-prod 5270ê±´, ë³´ì•ˆ ë¡œê·¸ 620ê±´"
       â”‚
       â”œâ”€â”€â†’ ê° Engine: should_i_run ì‘ë‹µì— ìµœì‹  ì§„ì°° ê²°ê³¼ í¬í•¨
       â”‚       â”œ Detect: "ë³´ì•ˆ ë¡œê·¸ 620ê±´ í™•ì¸ í•„ìš”"
       â”‚       â”œ Filter: "Noise 5800ê±´ â†’ í•„í„°ë§ ì¶”ì²œ"
       â”‚       â”œ Retain: "Class A 1920ê±´ â†’ Blob Archive í•„ìš”"
       â”‚       â”” Prevent: "Debug 5270ê±´ â†’ ê°œë°œíŒ€ì— ì•Œë¦¼ í•„ìš”"
       â”‚
       â””â”€â”€â†’ LLM Layer: ì§„ì°° ê²°ê³¼ ê¸°ë°˜ Suggestion ìƒì„±
               â”” "ì´ ë¡œê·¸ëŠ” Class Aë¡œ ì˜¬ë ¤ì•¼ í•©ë‹ˆë‹¤" ë“±
```

---

## 9. ì „ì²´ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨

```mermaid
graph TB
    subgraph "Azure Functions (function_app.py)"
        DT["ğŸ”µ diagnosis_trigger<br/>(QueueTrigger)"]
        ET1["ğŸŸ  detect_trigger<br/>(30ë¶„)"]
        ET2["ğŸŸ  prevent_trigger<br/>(6ì‹œê°„)"]
        ET3["ğŸŸ  retain_trigger<br/>(24ì‹œê°„)"]
        ET4["ğŸŸ  filter_trigger<br/>(On Demand)"]
    end

    subgraph "ğŸ”µ Diagnosis (agent/diagnosis/)"
        DR["DiagnosisRunner"]
        CO["Collector<br/>(KQL â†’ ì›ë³¸ ìˆ˜ì§‘)"]
        NO["Normalizer<br/>(ld_ ìŠ¤í‚¤ë§ˆ ë³€í™˜)"]
        CL["Classifier<br/>(ëª©ì /ì‹¬ê°ë„/ì¤‘ìš”ë„)"]
        DR --> CO --> NO --> CL
    end

    subgraph "ğŸŸ  Engines (agent/engines/)"
        DE["DetectEngine"]
        PE["PreventEngine"]
        RE["RetainEngine"]
        FI["FilterEngine"]
    end

    subgraph "Provider Cloud"
        PB["Provider Backend"]
        DB["Cosmos DB<br/>(ì§„ì°° ê²°ê³¼ + ì •ì±…)"]
        TM["Teams Dashboard"]
    end

    subgraph "ê³ ê°ì‚¬ ì¸í”„ë¼"
        QU["Storage Queue<br/>(diagnosis-requests)"]
        LAW["LAW"]
    end

    TM -->|"[ì§„ì°° ì‹¤í–‰] ë²„íŠ¼"| PB
    PB -->|"Queueì— ë©”ì‹œì§€"| QU
    QU --> DT --> DR
    CO -.->|KQL ì¿¼ë¦¬| LAW
    CL -->|ì§„ì°° ê²°ê³¼ ì „ì†¡| PB --> DB

    ET1 --> DE
    ET2 --> PE
    ET3 --> RE
    ET4 --> FI

    DB -.->|ì§„ì°° ê²°ê³¼ ì°¸ê³ | DE & PE & RE & FI
    DE & PE & RE & FI -->|ë¦¬í¬íŠ¸| PB
    PB --> TM
```

---

## 10. ì—ëŸ¬ í•¸ë“¤ë§

### ì§„ì°° ì¤‘ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì—ëŸ¬ì™€ ëŒ€ì‘

| ìƒí™© | ë°œìƒ ìœ„ì¹˜ | ëŒ€ì‘ |
| --- | --- | --- |
| LAW í…Œì´ë¸” ì—†ìŒ | Collector | `BadArgumentError` â†’ ê±´ë„ˆë›°ê³  ë‹¤ìŒ í…Œì´ë¸” ìˆ˜ì§‘ |
| KQL íƒ€ì„ì•„ì›ƒ | Collector | `PARTIAL` ìƒíƒœ â†’ ë¶€ë¶„ ê²°ê³¼ë¼ë„ í¬í•¨ |
| LAW ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ | Collector | `AuthenticationError` â†’ Providerì— ì—ëŸ¬ ë³´ê³ , Teams ì•Œë¦¼ |
| ì‹¬ê°ë„ í•„ë“œ ì—†ìŒ | Normalizer | `default_severity` ì‚¬ìš© |
| ë©”ì‹œì§€ ë„ˆë¬´ ê¹€ | Normalizer | 500ì ì´ˆê³¼ ì‹œ truncate |
| Queue ë©”ì‹œì§€ íŒŒì‹± ì‹¤íŒ¨ | function_app | JSON íŒŒì‹± ì‹¤íŒ¨ â†’ Dead Letter Queueë¡œ ì´ë™ |
| Provider í†µì‹  ì‹¤íŒ¨ | submit_diagnosis | ì¬ì‹œë„ 3íšŒ â†’ ì‹¤íŒ¨ ì‹œ ë¡œì»¬ ë¡œê·¸ì— ê¸°ë¡ |

### Dead Letter Queue

Queue ë©”ì‹œì§€ ì²˜ë¦¬ê°€ 5ë²ˆ ì‹¤íŒ¨í•˜ë©´ Azure Functionsê°€ ìë™ìœ¼ë¡œ `diagnosis-requests-poison` íë¡œ ì´ë™ì‹œí‚µë‹ˆë‹¤. ProviderëŠ” ì´ poison íë¥¼ ëª¨ë‹ˆí„°ë§í•˜ì—¬ Teamsì— ì•Œë¦¼ì„ ë³´ëƒ…ë‹ˆë‹¤.

---

## 11. êµ¬í˜„ ìˆœì„œ (ì¶”ì²œ)

| ìˆœì„œ | ëŒ€ìƒ | ëª¨ë“ˆ | ë‚œì´ë„ | LAW í•„ìš” | ì´ìœ  |
| :---: | :---: | --- | :---: | :---: | --- |
| 1 | ì§„ì°° | `mapping/table_registry.py` | ë‚®ìŒ | âŒ | ìˆœìˆ˜ ë°ì´í„° ì •ì˜ |
| 2 | ì§„ì°° | `normalizer.py` | ë‚®ìŒ | âŒ | ë³€í™˜ ë¡œì§, ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ |
| 3 | ì§„ì°° | `classifier.py` | ì¤‘ê°„ | âŒ | ì ìˆ˜ ê³„ì‚°, ê²½ê³„ê°’ ì¡°ì • |
| 4 | ì§„ì°° | `collector.py` | ì¤‘ê°„ | âœ… | LAW KQL ì—°ë™, í˜ì´ì§• |
| 5 | ì§„ì°° | `runner.py` | ë‚®ìŒ | âœ… | ìœ„ ëª¨ë“ˆ ì¡°í•© + ì§‘ê³„ |
| â€” | â€” | â€” | â€” | â€” | **â†‘ ì—¬ê¸°ê¹Œì§€ ì§„ì°°. â†“ ì—¬ê¸°ë¶€í„° ì—”ì§„.** |
| 6 | ì—”ì§„ | `detect.py` | ë†’ìŒ | âœ… | ë³´ì•ˆ ìœ„í˜‘ íƒì§€ ë¡œì§ |
| 7 | ì—”ì§„ | `retain.py` | ì¤‘ê°„ | âœ… | ë³´ì¡´ ì •ì±… + Blob export |
| 8 | ì—”ì§„ | `prevent.py` | ì¤‘ê°„ | âœ… | ë¡œê·¸ íŒ¨í„´ ë¶„ì„ |
| 9 | ì—”ì§„ | `filter.py` | ë†’ìŒ | âœ… | DCR ì œì–´ (ê°€ì¥ ë§ˆì§€ë§‰) |

> [!TIP] 1~3ë²ˆì€ LAW ì—°ë™ ì—†ì´ ìˆœìˆ˜ Pythonìœ¼ë¡œ êµ¬í˜„ + í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.
> ìƒ˜í”Œ JSONì„ ë§Œë“¤ì–´ì„œ `normalize â†’ classify` íŒŒì´í”„ë¼ì¸ì„ ë¨¼ì € ê²€ì¦í•˜ì„¸ìš”.

> [!TIP] ì§„ì°°(1~5ë²ˆ)ì„ ë¨¼ì € ì™„ì„±í•˜ë©´, ì—”ì§„ì„ í•˜ë‚˜ë„ ì•ˆ ë§Œë“¤ì–´ë„ **"í˜„ì¬ ê³ ê°ì‚¬ ë¡œê·¸ ìƒíƒœ ë¦¬í¬íŠ¸"** ê¸°ëŠ¥ì´ ë°”ë¡œ ë™ì‘í•©ë‹ˆë‹¤.
> Teams ëŒ€ì‹œë³´ë“œì—ì„œ "ë…¸ì´ì¦ˆ ë¹„ìœ¨ 37.6%, Debug ë¡œê·¸ 5270ê±´" ê°™ì€ í˜„í™©ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
